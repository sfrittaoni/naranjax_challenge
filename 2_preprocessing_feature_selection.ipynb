{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0dd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## funciones para cargar y grabar pickles\n",
    "def load_pickle(filename):\n",
    "    with open(filename,'rb') as file:\n",
    "        object_file = pickle.load(file)\n",
    "    return object_file\n",
    "\n",
    "def dump_pickle(file, filename):\n",
    "    with open(filename, \"wb\") as output_file:\n",
    "        pickle.dump(file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "df = pd.read_parquet(data_dir + 'application_train.parquet')\n",
    "agg_ccb = pd.read_pickle(data_dir + 'ccb_agg_features.pkl')\n",
    "agg_ip = pd.read_pickle(data_dir + 'ip_agg_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(agg_ccb, on = 'SK_ID_CURR', how='left')\n",
    "df = df.merge(agg_ip, on = 'SK_ID_CURR', how='left')\n",
    "\n",
    "del agg_ccb, agg_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = 'TARGET'\n",
    "id_col_name = 'SK_ID_CURR'\n",
    "\n",
    "y = df.pop(target_col_name)\n",
    "ids = df.pop(id_col_name)\n",
    "\n",
    "categorical_features = df.select_dtypes('object').columns.to_list()\n",
    "num_features = df.select_dtypes('number').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defino pipeline de preprocesamientos\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=np.nan))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo preprocesamiento\n",
    "X = preprocess.fit_transform(df)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "prepro_columns  = num_features + list(preprocess.transformers_[1][1][1].get_feature_names_out(categorical_features)) \n",
    "prepro_columns =  [x.replace(\" \", \"_\") for x in prepro_columns]\n",
    "X.columns = prepro_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone,_brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>WALLSMATERIAL_MODE_None</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>EMERGENCYSTATE_MODE_None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461.0</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765.0</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046.0</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005.0</td>\n",
       "      <td>-3039.0</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932.0</td>\n",
       "      <td>-3038.0</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0           0.0          202500.0    406597.5      24700.5         351000.0   \n",
       "1           0.0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2           0.0           67500.0    135000.0       6750.0         135000.0   \n",
       "3           0.0          135000.0    312682.5      29686.5         297000.0   \n",
       "4           0.0          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.018801     -9461.0         -637.0            -3648.0   \n",
       "1                    0.003541    -16765.0        -1188.0            -1186.0   \n",
       "2                    0.010032    -19046.0         -225.0            -4260.0   \n",
       "3                    0.008019    -19005.0        -3039.0            -9833.0   \n",
       "4                    0.028663    -19932.0        -3038.0            -4311.0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  ...  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0          -2120.0  ...                       0.0   \n",
       "1           -291.0  ...                       0.0   \n",
       "2          -2531.0  ...                       0.0   \n",
       "3          -2437.0  ...                       0.0   \n",
       "4          -3458.0  ...                       0.0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                            0.0                        0.0   \n",
       "1                            0.0                        0.0   \n",
       "2                            0.0                        0.0   \n",
       "3                            0.0                        0.0   \n",
       "4                            0.0                        0.0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone,_brick  \\\n",
       "0                       0.0                              1.0   \n",
       "1                       0.0                              0.0   \n",
       "2                       0.0                              0.0   \n",
       "3                       0.0                              0.0   \n",
       "4                       0.0                              0.0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_None  EMERGENCYSTATE_MODE_No  \\\n",
       "0                        0.0                      0.0                     1.0   \n",
       "1                        0.0                      0.0                     1.0   \n",
       "2                        0.0                      1.0                     0.0   \n",
       "3                        0.0                      1.0                     0.0   \n",
       "4                        0.0                      1.0                     0.0   \n",
       "\n",
       "   EMERGENCYSTATE_MODE_Yes  EMERGENCYSTATE_MODE_None  \n",
       "0                      0.0                       0.0  \n",
       "1                      0.0                       0.0  \n",
       "2                      0.0                       1.0  \n",
       "3                      0.0                       1.0  \n",
       "4                      0.0                       1.0  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set n rows: 206032\n",
      "Validation Set n rows: 50739\n",
      "Test Set n rows: 50740\n"
     ]
    }
   ],
   "source": [
    "ids_train, ids_val_test, X_train, X_val_test, y_train, y_val_test = train_test_split(ids, X, y, test_size=0.33, random_state=42)\n",
    "ids_val, ids_test, X_val, X_test, y_val, y_test = train_test_split(ids_val_test, X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
    "print(f'Train Set n rows: {X_train.shape[0]}')\n",
    "print(f'Validation Set n rows: {X_val.shape[0]}')\n",
    "print(f'Test Set n rows: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ids_val_test, X_val_test, y_val_test, df, y, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Best Than Random Feature approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c72b9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "canaritos_pct =  0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cad98ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar dataset con variables aleatorias\n",
    "def agregar_canaritos( pdataset, pcanaritos_idx ):\n",
    "    nrows, ncols= pdataset.shape\n",
    "    \n",
    "    \n",
    "    canaritos_cantidad = int(ncols * pcanaritos_idx)  \n",
    "    vcanaritos =  ['canarito_' + sub for sub in map(str, list(range(canaritos_cantidad)))]\n",
    "\n",
    "    np.random.seed(10217)\n",
    "\n",
    "    df_canaritos = pd.DataFrame(np.random.randn(nrows, canaritos_cantidad, ), columns=vcanaritos)\n",
    "    df_canaritos = df_canaritos.set_index(pdataset.index)\n",
    "\n",
    "    \n",
    "    result = pd.concat([pdataset, df_canaritos], axis=1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_con_canaritos = agregar_canaritos(X_train, canaritos_pct)\n",
    "X_val_con_canaritos = agregar_canaritos(X_val, canaritos_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4122a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(X_train_con_canaritos.columns).to_frame(name='feature' )\n",
    "\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "            \"reg_alpha\"   : [0.5,0.2,1],\n",
    "            \"reg_lambda\"  : [2,3,5],\n",
    "            \"gamma\"       : [1,2,3]}\n",
    "\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35fb28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:08:55<00:00, 773.57s/it] \n"
     ]
    }
   ],
   "source": [
    "### Realizo iteraciones para generar distintas feature importances\n",
    "\n",
    "n_iter = 10\n",
    "random.seed(42)\n",
    "for i in tqdm(range(n_iter)):\n",
    "    parms_iter = {k:random.choice(v) for k,v in params.items()}\n",
    "    model = XGBClassifier(seed=10,\n",
    "                          verbosity =0, \n",
    "                          objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          **parms_iter)\n",
    "    model.fit(X=X_train_con_canaritos, y=y_train)\n",
    "    \n",
    "    y_pred = model.predict_proba(X=X_val_con_canaritos)[:,1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_val,np.where(y_pred >0.5, 1,0))\n",
    "    roc_auc = roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    \n",
    "    feature_importance = pd.concat([feature_importance,  \n",
    "                                    pd.Series(model.feature_importances_).to_frame(name=f'importance_{i}' )],\n",
    "                                   axis=1)\n",
    "    feature_importance[f'ranking_{i}'] = feature_importance[f'importance_{i}'].rank(method='first', ascending = False)\n",
    "    \n",
    "    best_canarito = feature_importance.loc[feature_importance.feature.str.startswith('canarito')][f'ranking_{i}'].min() \n",
    "    \n",
    "    feature_importance[f'best_than_canarito_{i}'] = np.where(feature_importance[f'ranking_{i}'] < best_canarito, True, False) \n",
    "    \n",
    "    \n",
    "    metrics_iter = { 'iter': i,\n",
    "                    'accuracy':accuracy,\n",
    "                    'roc_auc':roc_auc,\n",
    "                    'params': parms_iter,\n",
    "                    'best_canarito' : best_canarito\n",
    "                   }\n",
    "    metrics.append(metrics_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame( metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53383354",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = metrics.loc[metrics.roc_auc == metrics.roc_auc.max(), 'params' ].values[0]\n",
    "dump_pickle(best_params, 'data/best_first_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe542978",
   "metadata": {},
   "source": [
    "#### Realizo el promedio de las 10 itereaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8edbca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_col = [col for col in feature_importance if col.startswith('importance_')]\n",
    "feature_importance['mean_importance'] = feature_importance[filter_col].mean(axis=1)\n",
    "feature_importance['ranking_mean_importance'] = feature_importance['mean_importance'].rank(method='first', ascending = False)\n",
    "best_mean_canarito = feature_importance.loc[feature_importance.feature.str.startswith('canarito')]['ranking_mean_importance'].min() \n",
    "feature_importance['best_than_canarito_mean'] = np.where(feature_importance['ranking_mean_importance'] < best_mean_canarito, True, False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c46f448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###selecciono las features que tuvieron un feature importance promedio mayor al de la mejor variable aleatoria\n",
    "feature_selected =feature_importance.loc[feature_importance['best_than_canarito_mean']]['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_pickle(data_dir + 'y_train.pkl')\n",
    "y_val.to_pickle(data_dir +  'y_val.pkl')\n",
    "y_test.to_pickle(data_dir + 'y_test.pkl')\n",
    "\n",
    "ids_train.to_pickle(data_dir + 'ids_train.pkl')\n",
    "ids_val.to_pickle(data_dir + 'ids_val.pkl')\n",
    "ids_test.to_pickle(data_dir + 'ids_test.pkl')\n",
    "\n",
    "X_train[feature_selected].to_pickle(data_dir + 'X_train.pkl')\n",
    "X_val[feature_selected].to_pickle(data_dir + 'X_val.pkl')\n",
    "X_test[feature_selected].to_pickle(data_dir + 'X_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
